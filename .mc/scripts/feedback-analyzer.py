#!/usr/bin/env python3
"""
ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼
å®Ÿè£…çµæœã‚’åˆ†æã—ã€å°†æ¥ã®é–‹ç™ºã«æ´»ã‹ã™ãŸã‚ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºã™ã‚‹
"""

import json
import os
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any

class FeedbackAnalyzer:
    def __init__(self, spec_name: str):
        self.spec_name = spec_name
        self.base_path = Path('.mc')
        self.results_path = self.base_path / 'results' / spec_name
        self.patterns_path = self.base_path / 'patterns'
        self.feedback_path = self.base_path / 'feedback'
        
        # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        self.patterns_path.mkdir(parents=True, exist_ok=True)
        self.feedback_path.mkdir(parents=True, exist_ok=True)
    
    def analyze_implementation(self, pr_number: int) -> Dict[str, Any]:
        """PR ã‹ã‚‰å®Ÿè£…ã‚’åˆ†æã—ã¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º"""
        analysis = {
            'pr_number': pr_number,
            'spec_name': self.spec_name,
            'timestamp': datetime.utcnow().isoformat(),
            'patterns': [],
            'insights': [],
            'recommendations': []
        }
        
        # ã‚¿ã‚¹ã‚¯å®Ÿè¡Œçµæœã‚’åé›†
        task_results = self._collect_task_results()
        
        # ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        code_patterns = self._analyze_code_patterns(task_results)
        analysis['patterns'].extend(code_patterns)
        
        # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        error_patterns = self._analyze_error_patterns(task_results)
        analysis['patterns'].extend(error_patterns)
        
        # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        success_patterns = self._analyze_success_patterns(task_results)
        analysis['patterns'].extend(success_patterns)
        
        # ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ç”Ÿæˆ
        analysis['insights'] = self._generate_insights(analysis['patterns'])
        
        # æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
        analysis['recommendations'] = self._generate_recommendations(analysis['patterns'])
        
        # åˆ†æçµæœã‚’ä¿å­˜
        self._save_analysis(analysis)
        
        return analysis
    
    def _collect_task_results(self) -> List[Dict[str, Any]]:
        """ã‚¿ã‚¹ã‚¯å®Ÿè¡Œçµæœã‚’åé›†"""
        results = []
        
        if self.results_path.exists():
            for result_file in self.results_path.glob('task-*/result.json'):
                with open(result_file, 'r') as f:
                    result = json.load(f)
                    result['file_path'] = str(result_file)
                    results.append(result)
        
        return results
    
    def _analyze_code_patterns(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        patterns = []
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³
        file_patterns = {}
        for result in results:
            if 'changes' in result:
                for change in result['changes']:
                    if change.get('type') == 'file_created':
                        file_type = Path(change['path']).suffix
                        file_patterns[file_type] = file_patterns.get(file_type, 0) + 1
        
        if file_patterns:
            patterns.append({
                'type': 'file_structure',
                'description': 'ã‚ˆãä½¿ç”¨ã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—',
                'data': file_patterns,
                'confidence': 0.8
            })
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³
        import_patterns = self._analyze_imports(results)
        if import_patterns:
            patterns.append({
                'type': 'imports',
                'description': 'ã‚ˆãä½¿ç”¨ã•ã‚Œã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«',
                'data': import_patterns,
                'confidence': 0.9
            })
        
        return patterns
    
    def _analyze_imports(self, results: List[Dict[str, Any]]) -> Dict[str, int]:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        imports = {}
        
        for result in results:
            if 'code_snippets' in result:
                for snippet in result['code_snippets']:
                    # Python imports
                    for match in re.findall(r'^import\s+(\w+)', snippet, re.MULTILINE):
                        imports[match] = imports.get(match, 0) + 1
                    for match in re.findall(r'^from\s+(\w+)', snippet, re.MULTILINE):
                        imports[match] = imports.get(match, 0) + 1
                    
                    # JavaScript/TypeScript imports
                    for match in re.findall(r'import\s+.*?\s+from\s+[\'"](.+?)[\'"]', snippet):
                        imports[match] = imports.get(match, 0) + 1
        
        return imports
    
    def _analyze_error_patterns(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        patterns = []
        error_types = {}
        
        for result in results:
            if result.get('status') == 'failed' and 'error' in result:
                error_type = result['error'].get('type', 'unknown')
                error_types[error_type] = error_types.get(error_type, 0) + 1
        
        if error_types:
            patterns.append({
                'type': 'errors',
                'description': 'é »å‡ºã™ã‚‹ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—',
                'data': error_types,
                'confidence': 0.95
            })
        
        return patterns
    
    def _analyze_success_patterns(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        patterns = []
        success_factors = {
            'test_coverage': [],
            'execution_time': [],
            'code_quality': []
        }
        
        for result in results:
            if result.get('status') == 'completed':
                if 'metrics' in result:
                    if 'test_coverage' in result['metrics']:
                        success_factors['test_coverage'].append(result['metrics']['test_coverage'])
                    if 'execution_time' in result['metrics']:
                        success_factors['execution_time'].append(result['metrics']['execution_time'])
                    if 'code_quality' in result['metrics']:
                        success_factors['code_quality'].append(result['metrics']['code_quality'])
        
        # å¹³å‡å€¤ã‚’è¨ˆç®—
        for factor, values in success_factors.items():
            if values:
                avg_value = sum(values) / len(values)
                patterns.append({
                    'type': 'success_factor',
                    'description': f'{factor}ã®å¹³å‡å€¤',
                    'data': {'average': avg_value, 'samples': len(values)},
                    'confidence': min(0.7 + len(values) * 0.05, 1.0)
                })
        
        return patterns
    
    def _generate_insights(self, patterns: List[Dict[str, Any]]) -> List[str]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ç”Ÿæˆ"""
        insights = []
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã«é–¢ã™ã‚‹ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        file_patterns = next((p for p in patterns if p['type'] == 'file_structure'), None)
        if file_patterns:
            most_common = max(file_patterns['data'].items(), key=lambda x: x[1])
            insights.append(f"æœ€ã‚‚é »ç¹ã«ä½œæˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã¯ {most_common[0]} ã§ã™ï¼ˆ{most_common[1]}å›ï¼‰")
        
        # ã‚¨ãƒ©ãƒ¼ã«é–¢ã™ã‚‹ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        error_patterns = next((p for p in patterns if p['type'] == 'errors'), None)
        if error_patterns:
            total_errors = sum(error_patterns['data'].values())
            insights.append(f"åˆè¨ˆ {total_errors} ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        # æˆåŠŸè¦å› ã«é–¢ã™ã‚‹ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        success_patterns = [p for p in patterns if p['type'] == 'success_factor']
        for pattern in success_patterns:
            if 'test_coverage' in pattern['description']:
                avg = pattern['data']['average']
                insights.append(f"å¹³å‡ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã¯ {avg:.1f}% ã§ã™")
        
        return insights
    
    def _generate_recommendations(self, patterns: List[Dict[str, Any]]) -> List[str]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
        recommendations = []
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«åŸºã¥ãæ¨å¥¨
        import_patterns = next((p for p in patterns if p['type'] == 'imports'), None)
        if import_patterns:
            top_imports = sorted(import_patterns['data'].items(), key=lambda x: x[1], reverse=True)[:3]
            recommendations.append(
                f"é »ç¹ã«ä½¿ç”¨ã•ã‚Œã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆ{', '.join([i[0] for i in top_imports])}ï¼‰ã¯"
                f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å«ã‚ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„"
            )
        
        # ã‚¨ãƒ©ãƒ¼ã«åŸºã¥ãæ¨å¥¨
        error_patterns = next((p for p in patterns if p['type'] == 'errors'), None)
        if error_patterns and error_patterns['data']:
            most_common_error = max(error_patterns['data'].items(), key=lambda x: x[1])
            recommendations.append(
                f"'{most_common_error[0]}' ã‚¨ãƒ©ãƒ¼ãŒæœ€ã‚‚é »ç¹ã«ç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚"
                f"ã“ã®ã‚¨ãƒ©ãƒ¼ã‚’é˜²ããŸã‚ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™"
            )
        
        # æˆåŠŸè¦å› ã«åŸºã¥ãæ¨å¥¨
        success_patterns = [p for p in patterns if p['type'] == 'success_factor']
        for pattern in success_patterns:
            if 'test_coverage' in pattern['description'] and pattern['data']['average'] < 80:
                recommendations.append(
                    "ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ80%æœªæº€ã§ã™ã€‚å“è³ªåŸºæº–ã‚’æº€ãŸã™ãŸã‚ã€"
                    "ã‚ˆã‚ŠåŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã®ä½œæˆã‚’æ¨å¥¨ã—ã¾ã™"
                )
        
        return recommendations
    
    def _save_analysis(self, analysis: Dict[str, Any]):
        """åˆ†æçµæœã‚’ä¿å­˜"""
        timestamp = datetime.utcnow().strftime('%Y%m%d-%H%M%S')
        
        # å€‹åˆ¥ã®åˆ†æçµæœã‚’ä¿å­˜
        analysis_file = self.feedback_path / f'analysis-{self.spec_name}-{timestamp}.json'
        with open(analysis_file, 'w') as f:
            json.dump(analysis, f, indent=2)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°
        patterns_db_file = self.patterns_path / 'patterns-db.json'
        if patterns_db_file.exists():
            with open(patterns_db_file, 'r') as f:
                patterns_db = json.load(f)
        else:
            patterns_db = {'patterns': [], 'last_updated': None}
        
        # æ–°ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½åŠ 
        patterns_db['patterns'].extend(analysis['patterns'])
        patterns_db['last_updated'] = analysis['timestamp']
        
        with open(patterns_db_file, 'w') as f:
            json.dump(patterns_db, f, indent=2)
        
        print(f"âœ… Analysis saved to {analysis_file}")
        print(f"ğŸ“Š Patterns database updated")

def main():
    """CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å®Ÿè£…çµæœã‚’åˆ†æã—ã¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º')
    parser.add_argument('--spec', required=True, help='ä»•æ§˜å')
    parser.add_argument('--pr', type=int, required=True, help='PRç•ªå·')
    
    args = parser.parse_args()
    
    analyzer = FeedbackAnalyzer(args.spec)
    analysis = analyzer.analyze_implementation(args.pr)
    
    # çµæœã‚’è¡¨ç¤º
    print("\nğŸ“Š åˆ†æçµæœ:")
    print(f"ä»•æ§˜: {analysis['spec_name']}")
    print(f"PR: #{analysis['pr_number']}")
    
    if analysis['insights']:
        print("\nğŸ’¡ ã‚¤ãƒ³ã‚µã‚¤ãƒˆ:")
        for insight in analysis['insights']:
            print(f"  - {insight}")
    
    if analysis['recommendations']:
        print("\nğŸ“ æ¨å¥¨äº‹é …:")
        for rec in analysis['recommendations']:
            print(f"  - {rec}")

if __name__ == '__main__':
    main()